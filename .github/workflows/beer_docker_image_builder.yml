name: Docker Image Builder

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches:
      - dev
      - integration
  workflow_call:
    inputs:
      branch_name:
        required: true
        type: string

      lambd_function_name:
        required: true
        type: string
    secrets:
      envPAT:
        required: true
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

env:
  #BUCKET_NAME : "github-oidc-test-mitch"
  AWS_REGION : "us-east-1"
  PROJECT_FILES_GIT : "beer-project-properties.git"
  ORGANIZATION: "pallcorporation"
  PROJECT_FILES_NAME: "project.properties"
  PROJECT_FILES_DIRECTORY: "project_file"
  IMAGE_REGISTRY: "ghcr.io"
  IMAGE_REGISTRY_USERNAME: ${{github.actor}}
  IMAGE_REGISTRY_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  

permissions:
      id-token: write
      contents: read    # This is required for actions/checkout@v1
      packages: write

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:  
  CommitAutomation:
    runs-on: ubuntu-latest
      
    #needs: FindAWSAccount
    steps:
        # Get current time stamp to use as reference elsewhere
        - name: Get current date
          id: date
          run: echo "::set-output name=date::$(date +'%Y%m%dT%H%M%S')"

        - name: Login to docker
          if: |
            ${{ steps.skip_everything.outputs.skip_everything1 != 'true' && steps.skip_dk_build.outputs.bypass_dk_build !='true' && steps.get_deployment_type.outputs.deployment_type == 'image' && steps.get_cdk_destroy_stack.outputs.cdk_destroy_stack != 'true'}}
          uses: docker/login-action@v1
          with:
            registry: ${{env.IMAGE_REGISTRY}}
            username: ${{env.IMAGE_REGISTRY_USERNAME}}
            password: ${{env.IMAGE_REGISTRY_TOKEN}}
        
        # Clone repositories prior to work
        - name: Git clone the repository
          uses: actions/checkout@v1

        - name: Make project files directory
          run: mkdir ${{env.PROJECT_FILES_DIRECTORY}}
        
        - name: Project files clone
          uses: actions/checkout@v2
          with:
            token: ${{ secrets.envPAT }}
            repository: pallcorporation/beer-project-properties
            ref: main
            path: ${{env.PROJECT_FILES_DIRECTORY}}

        
        # Grant permissions to all files in directory
        - name: Grant permissions to all files
          run: chmod -R 755 ./  
        
        # Get branch name to use for look up
        - name: Branch name
          id: get_branch_name
          run: |
            echo "##[set-output name=branch_name;]$(echo ${{inputs.branch_name}})"
            echo ${{ steps.get_branch_name.outputs.branch}}
            ls
        
        # Read of project files and set to variables
        - name: Get project constants from project.properties repo - Branch name, deployment role, skip cdk, destroy stack
          id: project_constants
          run: |
            account_id="`grep aws_${{ steps.get_branch_name.outputs.branch_name }}_account ${{env.PROJECT_FILES_NAME}}|cut -d'=' -f2`"
            echo "::set-output name=env_id::${account_id}"
            
            oidc_role_name="`grep aws_${{ steps.get_branch_name.outputs.branch_name }}_oidc_role_name ${{env.PROJECT_FILES_NAME}}|cut -d'=' -f2`"
            echo "::set-output name=oidc_role::${oidc_role_name}"

            cdk_deploy_role_arn="`grep aws_${{ steps.get_branch_name.outputs.branch_name }}_cdk_deployment_role ${{env.PROJECT_FILES_NAME}}|cut -d'=' -f2`"
            echo "::set-output name=cdk_deploy::${cdk_deploy_role_arn}"
            
            aws_bucket="`grep aws_frontend_bucket ${{env.PROJECT_FILES_NAME}}|cut -d'=' -f2`"
            echo "::set-output name=aws_bucket_name::${aws_bucket}"
            echo $aws_bucket

            cloud_front_id="`grep aws_${{ steps.get_branch_name.outputs.branch_name }}_cloudfront_id ${{env.PROJECT_FILES_NAME}}|cut -d'=' -f2`"
            echo "::set-output name=aws_cloud_front_id::${cloud_front_id}"
          working-directory: ${{env.PROJECT_FILES_DIRECTORY}}

        
        
        # Get deployment type
        - name: Get deployment type
          id: get_deployment_type
          run: |
            echo "##[set-output name=deployment_type;]$(echo ${{inputs.deployment_type}})"
            echo ${{ steps.get_deployment_type.outputs.deployment_type}}

        
        # Read commit message and determine if to skip docker work
        - name: Read if to skip image build & deployment based on commit message
          id: skip_dk_build
          if: "contains(github.event.head_commit.message, '+image-skip')"
          run: |
            echo "We will node installation"
            echo "::set-output name=bypass_dk_build::true"


        # Role that will be used for OIDC. This is the role this session will assume when connecting to AWS         
        - name: Arn to use
          id: aws_assume_role
          run: |
            echo "::set-output name=role_arn1::arn:aws:iam::${{ steps.project_constants.outputs.env_id }}:role/${{ steps.project_constants.outputs.oidc_role}}"
      
        - name: Configure AWS credentials
          uses: aws-actions/configure-aws-credentials@master
          with:
            role-to-assume: ${{steps.aws_assume_role.outputs.role_arn1}}
            role-session-name: ${{ github.event.repository.name }}-${{ steps.date.outputs.date }}
            aws-region: ${{ env.AWS_REGION }}

        #- name: Github Tag with semantic versioning
        #  if: github.ref == 'refs/heads/main' && contains(github.event.head_commit.message, '+tag-skip') != true
        #  id: version_number
        #  uses: hennejg/github-tag-action@v4.3.1
        #  with:
        #    github_token: ${{ secrets.GITHUB_TOKEN }}
        #    default_bump: minor
        #    tag_prefix: v
        #    release_branches: main

        - name: Version number
          #if: github.ref == 'refs/heads/main' && contains(github.event.head_commit.message, '+tag-skip') != true
          run: |
            echo "${{ steps.date.outputs.date }} is the new version"
            echo "TAG_VERSION=${{ steps.date.outputs.date }}" >> $GITHUB_ENV
 
        # Node installation (if required)
        - name: Setup node.js environment
          uses: actions/setup-node@v2.1.2

        - name: Install yaml
          run: |
            pip install pyyaml
        
        - name: Remove existing project if commited, replace with master version
          run: |
            ls
            echo "Moving file to current directory.."
            rm -f -- ${{env.PROJECT_FILES_NAME}}
            cp ${{env.PROJECT_FILES_DIRECTORY}}/${{env.PROJECT_FILES_NAME}} .
            echo "done moving file to current directory.."
            ls
        - name: ECR Registry
          id: ecr_registry
          run: |
            DOCKER_TAG_VERSION="${{ steps.project_constants.outputs.env_id }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ github.event.repository.name }}:$IMAGE_VERSION"
            DOCKER_TAG_LATEST="${{ steps.project_constants.outputs.env_id }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ github.event.repository.name }}:latest"
        
        - name: Build Docker images
          id: build_images
          run: |
            docker build . -t $DOCKER_TAG_VERSION
            docker tag $DOCKER_TAG_VERSION $DOCKER_TAG_LATEST

        - name: ECR Login
          id: ecr_login
          run: |
            aws ecr describe-repositories --repository-names ${{ github.event.repository.name }} || aws ecr create-repository --repository-name ${{ github.event.repository.name }}
            aws ecr get-login-password --region ${{ env.AWS_REGION }}| docker login --username AWS --password-stdin ${{ steps.project_constants.outputs.env_id }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com

        #- name:  Build image and deploy to registry
        #  id: docker_image_info
        #  run: |
        #    echo "Deploying image"
        #    IMAGE_VERSION=$TAG_VERSION
        #    GHCR_IMAGE_ID=ghcr.io/${{github.repository_owner}}/${{ github.event.repository.name }}:$IMAGE_VERSION
        #    docker build . -t $GHCR_IMAGE_ID    
        #    echo "::set-output name=ghcr_image_id::$GHCR_IMAGE_ID"

    #        LOCAL_IMAGE_ID=${{ github.event.repository.name }}:$IMAGE_VERSION
    #        docker build . -t $LOCAL_IMAGE_ID
    #        echo "::set-output name=local_image_id::$LOCAL_IMAGE_ID"   
  
        #- name: Push docker image to GHCR
        #  if: ${{ steps.get_deployment_type.outputs.deployment_type == 'image'}}
          #run: docker push ${{ steps.docker_image_info.outputs.ghcr_image_id}}
        - name: Push docker image to ECR
          run: |
            docker push $DOCKER_TAG_VERSION
            docker push $DOCKER_TAG_LATEST

        - name: Update function with new image built
        #  if: ${{ steps.skip_everything.outputs.skip_everything1 != 'true' && steps.get_deployment_type.outputs.deployment_type == 'image' && steps.get_cdk_destroy_stack.outputs.cdk_destroy_stack != 'true'}}
          run: |
            aws lambda update-function-code --region ${{ env.AWS_REGION }} --function-name ${{inputs.lambd_function_name}} --image-uri $DOCKER_TAG_VERSION
    outputs:
      #env_name: ${{ steps.branch_check.outputs.env_id }}tt
      #role_arn: ${{ steps.aws_assume_role.outputs.role_arn1}}
      cdk_check: ${{ steps.check_cdk.outputs.cdk_found}}
      env_name: ${{ steps.project_constants.outputs.env_id }}
      oidc_role: ${{ steps.project_constants.outputs.oidc_role}}
      skip_cdk: ${{ steps.skip_cdk.outputs.bypass_cdk}}
      cdk_deploy_name: ${{ steps.project_constants.outputs.cdk_deploy}}
      cdk_destroy_stack_bool: ${{ steps.project_constants.outputs.cdk_destroy_stack}}
      role_arn: ${{ steps.aws_assume_role.outputs.role_arn1}}
      branch_name: ${{ steps.get_branch_name.outputs.branch_name}}
      aws_upload_bucket: ${{steps.project_constants.outputs.aws_bucket_name}} 