name: CI

# Controls when the workflow will run
on:
  # Triggers the workflow on push 
  push:
   branches:
     - dev
     - beta
     - prod
  workflow_call:
    inputs:
      APP_NAME:
        type: string
      ARTIFACT_NAME:
        type: string
      ARTIFACT_DESCRIPTION:
        type: string

    secrets:
      envPAT:
        required: true
      PY_KEY:
        required: true
      APP_SIGN_KEY:
        required: true

        
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

env:
  #BUCKET_NAME : "github-oidc-test-mitch"
  AWS_REGION : "us-east-1"
  PROJECT_FILES_GIT : "beer-project-properties.git"
  ORGANIZATION: "pallcorporation"
  PROJECT_FILES_NAME: "project.properties"
  PROJECT_FILES_DIRECTORY: "project_file"
  CDK_MODULE: "cdk_checkedout"
  DEVOPS_STORE: "devops_store"
  CODEBUILD_BUILD_NUMBER: "1" # semantic versioning injected here
  ARTIFACT_NAME: ${{ inputs.ARTIFACT_NAME }}
  APP_NAME: ${{ inputs.APP_NAME}}
  ARTIFACT_DESCRIPTION: ${{ inputs.ARTIFACT_DESCRIPTION }}
  PY_KEY: ${{ secrets.PYINSTALLER_KEY}}
  APP_SIGN_KEY: ${{ secrets.OENO_APP_SIGN_KEY}}




  

permissions:
      id-token: write
      contents: read    # This is required for actions/checkout@v1
      packages: write

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:  
  AWS-WIN-EXE-BUILD:
    if: github.repository != 'pallcorporation/digital-iot-devops-store'
    runs-on: windows-2019
      
    steps:
        # Get current time stamp to use as reference elsewhere
        - name: Get current date
          id: date
          run: |
            echo ::set-output name=date::$(date +'%Y%m%dT%H%M%S')  
        
        - name: Git clone the repository
          uses: actions/checkout@v2

        - name: Set up build env
          run: |
            python --version
            python -m venv env
            env\scripts\Activate

        - name: Install dependencies
          run: |    
            env\scripts\pip install -r requirements.txt
            env\scripts\pip install pyinstaller pyinstaller[encryption] tinyaes

        - name: Copy static assets
          run: |
            cp -r env\Lib\site-packages\dash* env\Include
            ls env\Include

        - name: Generate version info 
          run: |
            python generateVersionInfo.py -v "${{env.CODEBUILD_BUILD_NUMBER}}" -n "${{env.APP_NAME}}" -d "${{env.ARTIFACT_DESCRIPTION}}"
            
        - name: Build encrypted exe via Pyinstaller    
          run: |
            cd service
            ..\env\scripts\pyinstaller -y --icon .\assets\icon.ico --version-file .\assets\versioninfo --onefile --add-data "../env/Include;./" --key="${{env.PY_KEY}}" ${{ env.APP_NAME }}.py

        - name: Sign application
          run: |
            cd service 
            C:\"Program Files (x86)"\"Windows Kits"\10\bin\x64\signtool.exe sign /debug /F ..\oenoflow_prod.pfx /P "${{ env.APP_SIGN_KEY }}" /T http://timestamp.digicert.com ..\service\dist\${{ env.ARTIFACT_NAME }}
        
        - name: Bundle deployment assets
          run: |
            cp .\service\dist\${{ env.ARTIFACT_NAME }} .\ota\${{ env.ARTIFACT_NAME }}
            

        - uses: actions/upload-artifact@v2
          with:
            name: ${{ env.APP_NAME }}
            path: ota/
            
        # Next steps to upload file to S3 softwarepackages- for beta or prod
        # if branch == beta || prod
        #   upload ota/* zip to ^^above archive to packageUpdates/appname

  
        
        
        # Upload a file to AWS s3
        # - name:  Deploy to S3 - Copy Build folder to s3
        # #  if: ${{ steps.skip_everything.outputs.skip_everything1 != 'true' && steps.skip_npm.outputs.bypass_npm !='true' && steps.get_deployment_type.outputs.deployment_type == 'web' && steps.get_cdk_destroy_stack.outputs.cdk_destroy_stack != 'true' }}
        #   run: |
             #aws s3 cp urls.json s3://${{inputs.hosting_bucket}}-${{env.AWS_ENV_NAME}}



        

